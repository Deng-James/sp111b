# 五子棋AI
聲明 : 此專案參考自 https://github.com/lihongxun945/gobang  
語言 : JavaScript  
五子棋連結 : http://gobang.light7.cn/#/  

## 深藍（Deep Blue）
深藍（Deep Blue）是由IBM開發，專門用以分析西洋棋的超級電腦。1997年5月曾擊敗西洋棋世界冠軍卡斯帕羅夫。  

1997年深藍以一分總比優勢戰勝當時的國際象棋之王卡斯帕羅夫，這是電腦第一次在棋類中戰勝頂尖人類選手，讓世人見證了人工智能的威力。在此以後，計算機逐漸統治了除圍棋以外的大部分棋類游戲。

深藍為1270平方米，擁有32個大腦（微處理器），每秒可計算2億步。

## 圍棋難題
我們把這個複雜度叫做空間複雜度，由於圍棋的複雜度太高，因此很難在較短的步驟內評估出合適的走法，而且也很難搜索到較深的深度。  

更直觀點說，圍棋的難點在於兩部分：  
圍棋本身的局面評估很複雜，不像象棋一樣可以簡單的給每個子打一個分。圍棋更注重“局勢”，非常難用常規手段打分。由於連評分都不准，因此搜索的基礎都不可靠。
圍棋很難達到較深的深度，因為圍棋每一步的可能性非常多，平均一步需要考慮100+種可能，因此很難達到較深的搜索深度。

![image](https://github.com/Deng-James/sp111b/assets/55796905/8374d665-3c01-4022-9787-9f6701a98ccc)

## AlphaGO 強化學習  
AlphaGO 通過兩個神經網絡，分別解決了這兩個問題。  

策略網路（Policy Network）是一種在強化學習中常用的人工神經網路模型，在特定環境中做出最佳動作的策略。策略網絡可以產生更少的分支，預測更合理的做法  

價值網路（ Value Network ）是在強化學習中常用的另一種人工神經網路模型，用於評估環境狀態的價值或期望回報。價值網絡可以比較準確的進行局勢的評分  
![image](https://github.com/Deng-James/sp111b/assets/55796905/399e1ddd-7f2b-438e-8302-6e977b99925e)

## 極大極小值搜尋演算法
五子棋看起來有各種各樣的走法，而實際上把每一步的走法展開，就是一顆巨大的博弈樹。在這個樹中，從根節點為0開始，奇數層表示電腦可能的走法，偶數層表示玩家可能的走法。

那麼我們如何才能知道哪一個分支的走法是最優的，我們就需要一個評估函數能對當前整個局勢作出評估，返回一個分數。我們規定對電腦越有利，分數越大，對玩家越有利，分數越小，分數的起點是0。

電腦走棋的層我們稱為 MAX層，這一層電腦要保證自己利益最大化，那麼就需要”選分最高”的節點。 

玩家走棋的層我們稱為MIN層，這一層玩家要保證自己的利益最大化，那麼就會”選分最低”的節點。  

此圖中甲是電腦，乙是玩家，那麼在甲層的時候，總是選其中值最大的節點，乙層的時候，總是選其中最小的節點。   
而每一個節點的分數，都是由子節點決定的，因此我們對博弈樹只能進行深度優先搜索而無法進行廣度優先搜索。
深度優先搜索用遞歸非常容易實現，然後主要工作其實是完成一個評估函數，這個函數需要對當前局勢給出一個比較準確的評分。
![image](https://github.com/Deng-James/sp111b/assets/55796905/792af98a-5d12-4722-b2d4-6c15ff2f34a1)


## 函數評分方式
五子棋的評分是簡單的把棋盤上的各種連子的分值加起來得到的，對各種連子的基本評分規則如下：  
連五 100000  
活四 10000  
活三 1000  
活二 100   
活一 10  

如果一側被封死但是另一側沒有，則評分降一個檔次，也就是死四和活三是相同的分  
死四 1000  
死三 100  
死二 10  
![image](https://github.com/Deng-James/sp111b/assets/55796905/3741c84c-4d86-4dd6-a316-4b87e6cfbb60)
![image](https://github.com/Deng-James/sp111b/assets/55796905/6e284524-8d4a-44a8-96fe-5eb5c4b22324)

## Alpha Beta 剪枝演算法
剪枝原理：在博弈樹搜索過程中，Alpha-Beta剪枝可以消除一些不必要的搜索。當某個節點的值已經超出Alpha和Beta之間的範圍時，可以提前終止搜索。 

Alpha更新：在最大化玩家的節點中，如果找到的節點值大於Alpha，則更新Alpha的值為該節點的值。

Beta更新：在最小化玩家的節點中，如果找到的節點值小於Beta，則更新Beta的值為該節點的值。

剪枝條件：當在搜索過程中發現到Beta小於等於Alpha時，表示該分支不會影響最終結果，可以提前停止該分支的搜索，進行剪枝。  

Alpha-Beta剪枝的主要優點是它可以大大減少搜索的節點數量，從而提高搜索速度。它適用於那些具有高度分支因子的博弈樹，並能夠在保證正確性的同時大幅度減少計算時間。
![image](https://github.com/Deng-James/sp111b/assets/55796905/1e60ff8c-c096-473c-9750-5cb352168e6e)
![image](https://github.com/Deng-James/sp111b/assets/55796905/60d31e0c-5c96-4c1b-a11d-52e80626e073)

## 性能優化的重要性
棋力 = 搜索深度，我們要提升電腦的棋力，最直接方式就是加大搜索深度。但是搜索深度每加深一層，時間會提升大約 20 倍，如果8層深度需要20秒，那麼10層將會需要 20*20*20 = 8000秒 超過了一個小時，這顯然是不能接受的。因此我們需要盡可能優化搜索的性能，提升速度，以達到更大的搜索深度。

### 評估函數的局部刷新
如圖，假設我們走了25，那麼只會在它的”米字”方向上的幾個位置的分數會發生變化
其餘的大部分棋子分數不會有任何變化。  
因此當我們更新分數的時候，只需要更新這7個點即可，而不是更新24個點的分數。  
這樣能大幅降低計算量。  
![image](https://github.com/Deng-James/sp111b/assets/55796905/944ce50f-bf39-4087-8e58-07447d8cebfc)

## 米子進攻路徑優化
現在我們每一層搜索，都會遍歷所有的可能的點  
但事實上，任何一方的進攻，其實並不是雜亂的  
一般情況下，它的連續進攻路線都可以用一條折線鏈接起來，其中每一個節點都在上一個節點的米子方向上。  
這樣做可以大幅減少需要計算的點。  
![image](https://github.com/Deng-James/sp111b/assets/55796905/03da4a79-d443-4b50-9697-6da713e6f0ef)


